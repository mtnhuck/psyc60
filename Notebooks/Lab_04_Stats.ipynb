{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics and Visualization Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dartmouth College, Psych 60\n",
    "\n",
    "Professor Jeremy Huckins\n",
    "\n",
    "TA Alex daSilva\n",
    "\n",
    "__For each question in this lab please post your answers to the canvas discussion for Lab 04 when you are done.__\n",
    "\n",
    "As you well know, statistics are extremly important science in general, but, one could argue that without statistics fMRI would be relatively useless. Much of what we do  here you will want to do for your class project, so please take some time to read and understand each part as best you can.\n",
    "\n",
    "### GLM\n",
    "\n",
    "In Lab 03, we calculated first-level fixed-effects general linear model by accounting for:\n",
    "\n",
    "When the the movie was on VS off (1st column)\n",
    "\n",
    "Motion (next 6 columns)\n",
    "\n",
    "Run (next columns, remember we had 2 runs)\n",
    "\n",
    "<img src=\"Images/Lab_03_MOVIEON_GLMa.png\"></img>\n",
    "\n",
    "This accounts for __within subject variability__\n",
    "\n",
    "If you would like more information outside of what we covered in class check [this out](http://www.fil.ion.ucl.ac.uk/spm/course/slides10-vancouver/02_General_Linear_Model.pdf)\n",
    "\n",
    "\n",
    "\n",
    "### RFX\n",
    "\n",
    "In Lab 03, we also calculated random effects, abbreviated as RFX in SPM. RFX allows us to extrapolate the results from our group of subjects to a population of subjects drawn from a similar pool.\n",
    "\n",
    "This accounts for __between subject variability__\n",
    "\n",
    "\n",
    "### Summary of the SPM Analysis Pipeline\n",
    "Here is a nice summary of SPM's analysis pipeline: http://www.sbirc.ed.ac.uk/cyril/SPM-course/Talks/2013/2-RFX_%20AM.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconnect to your VNC session\n",
    "\n",
    "Use ScreenShare (Mac) or TightVNC (PC) to reconnect to your VNC session. \n",
    "\n",
    "If your old session timed out start a new one as described in earlier labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View your results from Lab 03\n",
    "\n",
    "Open up matlab if you don't already have it opened by typing 'spm12' then open 'xjview' \n",
    "\n",
    "Once xjview is open load the results of your GLM analysis - looking at the con(trast) file  for movie on vs movie off for a single subject. Now that you have it open take a look around and see which brain areas showed activation VS deactivation in the movie. \n",
    "\n",
    "1. How many regions do you have? (hint click `Report`)\n",
    "\n",
    "2. Can you tell if these regions would pass a significance test? If so, how?\n",
    "\n",
    "3. What `p-value` and `cluster size` does xjview list?\n",
    "\n",
    "4. What happens when you change the `p-value` or `cluster size`? How many regions do you have now?\n",
    "\n",
    "5-8. Now load the results of your RFX analysis (group-level) and report your answers for the above questions. \n",
    "\n",
    "9. What is similar between the individual (GLM) and group (RFX) level analyses?\n",
    "\n",
    "10. What is different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FDR\n",
    "\n",
    "FDR, or false discovery rate, is a method designed to control the expected proportion of \"discoveries\" or \"hits\"(rejected null hypotheses) that are false (incorrect rejections). In our case, this would be trying to control how many voxels are below are p-value threshold that are below this threshold based on random chance, not a real phenomea we are observing.\n",
    "\n",
    "If you don't already have your RFX results loaded, load them in xjview now. Set your `pValue` to 0.05 and `cluster size` to 5. \n",
    "\n",
    "11. Observe the relative amount of regions that pass the thresholds you set. Click `report` to quantify this.\n",
    "\n",
    "Next set `FDR p=` to 0.05.\n",
    "\n",
    "12. What happened visually?\n",
    "\n",
    "13. Run the `report` again and see how much things changed.\n",
    "\n",
    "14. Are you seeing regions that are associated with movie on or movie off? What happens if you change the switch from `Only +` to `Only -`? What about to `All`? What is going on here?\n",
    "\n",
    "If you want to do further reading on FDR I would suggest this:\n",
    "https://archive.is/20120712123608/http://dx.doi.org/10.1146/annurev.ps.46.020195.003021\n",
    "\n",
    "\n",
    "When you are done clear the values in FDR p= then click on a different box, say pValue and the results should show up as before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Correction\n",
    "\n",
    "There is a wide-range of values you could use for voxelwise p-value thresholds or cluster size - which is correct or optimal?\n",
    "\n",
    "To account for multiple comparisons we are going to run an analysis to identify some pairs of p-value and cluster-size thresholds to try to keep us away from the bad side of multiple comparisons (identifying regions that are actually just noise) without being too strict (e.g. setting the cluster size to be too large and missing out on real results). Remember, if you change the p-value, that will change the cluster-size that you need to identify real results without too many false positives.\n",
    "\n",
    "The script we are going to run does a few things:\n",
    "- Estimates the shape of the noise in our data from the residuals in our RFX analysis\n",
    "- Estimates the average noise across subjects\n",
    "- Submits these parameters to a permutation testing algorithm which then sees how often you would see clusters of a certain size above a given p-value threshold\n",
    "\n",
    "To run volume correction:\n",
    "\n",
    "First move into the directory that your RFX results are in. (cd, ls and pwd are friends)\n",
    "\n",
    "Copy the script to your home directory: `!cp ~/../ACF_Volume_Correction.m ~/matlab/`\n",
    "The `!` just means that the command will run from the terminal instead of through matlab.\n",
    "\n",
    "Run the script - Make sure you are in the RFX directory still. `ACF_Volume_Correction` then enter\n",
    "\n",
    "This will run AFNI's 3dClustSim (more information here: https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dClustSim.html)\n",
    "\n",
    "As you can see, there are many options. The code above is just a wrapper to run it with a few combinations of p-value and cluster size thresholds.\n",
    "\n",
    "__This may take a while to run... take a break, grab a quick coffee etc.__\n",
    "\n",
    "When it is finished type `ls` to view the files in the directory. You want `3dClustSimResults.NN2_2sided.1D`. \n",
    "\n",
    "To view the contents of this file type `!gedit ./3dClustSimResults.NN2_2sided.1D`\n",
    "\n",
    "You should see something similar to this:\n",
    "\n",
    "<img src=\"Images/Lab_04_3dClustSimOutput.png\"></img>\n",
    "\n",
    "\n",
    "The pValue thresholds are listed as rows and the cluster size thresholds are listed as columns. If you want to do volume correction to p<0.05, go down the first column and find the voxel-level pvalue threshold, say 0.01. For this example you would use a pvalue of 0.01 in xjView with a cluster size of 72.\n",
    "\n",
    "15. Why do we do volume correction?\n",
    "\n",
    "16. How many regions do you have if you do volume correction to p<0.05 using a voxel-level threshold of 0.05? (Remember the `report` button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting results\n",
    "\n",
    "When reporting whole-brain fMRI results people often report the following:\n",
    "Brain region (anatomically derived), Cluster Size, Peak T (or Z), X, Y, Z\n",
    "\n",
    "The following link as a good example of fMRI results tables:\n",
    "http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0185-14.2014\n",
    "\n",
    "\n",
    "To report results in a similar table in a semi-automated way do the following:\n",
    "\n",
    "-Have your image loaded and volume-corrected to your selected thresholds\n",
    "\n",
    "-Click the `volume` button next to the `report` button you have previously used. It will prompt you for a SPM.mat file - you want to navigate and select the SPM.mat file in your RFX analysis directory. A table will appear - you can right click and export the table, take a screen shot of it etc.\n",
    "\n",
    "For the class project your results should be reported in a table generated as above, along with anatomical regions of the peaks, which can be generally identified using xjView, going to the coordinates then looking at what is listed below the brain images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now you have results... how do you interpret them?\n",
    "\n",
    "With your RFX file loaded, and your pValue and cluster size values entered start clicking around (navigation is in the top right window, or up/down left/right or +/- on your keyboard)\n",
    "\n",
    "<img src=\"Images/Lab_04_InfoMapTD05_LM.png\"></img>\n",
    "\n",
    "\n",
    "<img src=\"Images/Lab_04_InfoMapTD05_LM_Labels.png\"></img>\n",
    "\n",
    "\n",
    "17. What regions/networks/systems would the positive regions (more brain activity during movie on VS movie off) be part of (see above)?\n",
    "\n",
    "18. Negative regions/networks/systems?\n",
    "\n",
    "### Neurosynth\n",
    "\n",
    "You can take the coordinate at some of your peaks and run them through http://neurosynth.org/\n",
    "This will give you and idea of what kinds of terms were often observed across other papers in that location, what other papers had peaks near your peak and also the resting-state functional connectivity from that region.\n",
    "\n",
    "Neurosynth also has a decoder where it looks what what your statistical image is most similar to. This is what I used for comparing NAcc resting-state maps with terms in the last lecture.\n",
    "\n",
    "<img src=\"Images/Lab_04_Decoder.png\"></img>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing your results\n",
    "\n",
    "There are a few options for visualizing your results once you have found a p-value and volume that you are going to use.\n",
    "\n",
    "### xjView\n",
    "\n",
    "Surprise, surprise, xjView, which we use to threshold and view our images is very useful for creating high quality images of our results for the purposes.\n",
    "\n",
    "With your RFX file loaded, and your pValue and cluster size values entered, click `slice view`. Select a view, the number of slices and the slice thickness (mm between slices). \n",
    "\n",
    "There are two ways you save your image. First you can take a screenshot on your mac or pc. Second, click `File` (Top left) then `Save Figure As...` \n",
    "One caveat to the second method... if you save it on the server you need to use a sftp client to transfer the file to your computer. \n",
    "PC: You should be able to use the same program that you use for ssh to transfer the files\n",
    "PC or MAC: FileZilla is a personal favorite although there are many options out there. https://filezilla-project.org/\n",
    "\n",
    "Files you save to your home directory or desktop can be found under `/afs/dbic.dartmouth.edu/usr/pkg/PBS60/pbs60yourletter/`\n",
    "\n",
    "19. Please take a screenshot of your volume corrected results displayed through slice view and upload them to canvas along with your answers to other questions.\n",
    "\n",
    "### HCP workbench \n",
    "\n",
    "Workbench is a great option to make beatiful visuals, but it does take some more effort. While not required for class, it is an great way to visualize your data from your personal computer if you are so motivated.\n",
    "\n",
    "Download:\n",
    "https://www.humanconnectome.org/software/get-connectome-workbench\n",
    "Tutorials:\n",
    "https://www.humanconnectome.org/software/get-connectome-workbench#documentation\n",
    "Template brain (download the 32 or 164k version):\n",
    "http://brainvis.wustl.edu/wiki/index.php//Caret:Atlases/Conte69_Atlas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
